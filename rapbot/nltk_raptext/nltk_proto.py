import nltk

from nltk.tokenize import word_tokenize

#text = open("home/user/Downloads/...")
tokens = word_tokenize(text)
print(tokens)

# define a function with parts of tokenized speech
#def tokenized():
#    text = tokenize(text)
i
